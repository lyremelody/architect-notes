---
title: '智能计算发展史'
linkTitle: '智能计算发展史'
type: 'docs'
weight: 102
bookFlatSection: true
bookHidden: false
date: 2024-05-30
isCJKLanguage: true
params:
  author: lyremelody
---

智能计算包括人工智能技术与它的计算载体，大致历经了四个阶段，分别为通用计算装置、逻辑推理专家系统、深度学习计算系统、大模型计算系统。

## 通用自动计算装置(1946年)
智能计算的起点是通用自动计算装置(1946年)。艾伦·图灵（Alan Turing）和冯·诺依曼（John von Neumann）等科学家，一开始都希望能够模拟人脑处理知识的过程，发明像人脑一样思考的机器，虽未能实现，但却解决了计算的自动化问题。通用自动计算装置的出现，也推动了1956年人工智能（AI）概念的诞生，此后所有人工智能技术的发展都是建立在新一代计算设备与更强的计算能力之上的。

## 逻辑推理专家系统(1990年)
智能计算发展的第二阶段是逻辑推理专家系统(1990年)。E.A.费根鲍姆（Edward Albert Feigenbaum）等符号智能学派的科学家以逻辑和推理能力自动化为主要目标，提出了能够将知识符号进行逻辑推理的专家系统。人的先验知识以知识符号的形式进入计算机，使计算机能够在特定领域辅助人类进行一定的逻辑判断和决策，但专家系统严重依赖于手工生成的知识库或规则库。这类专家系统的典型代表是日本的五代机和我国863计划支持的306智能计算机主题，日本在逻辑专家系统中采取专用计算平台和Prolog这样的知识推理语言完成应用级推理任务；我国采取了与日本不同的技术路线，以通用计算平台为基础，将智能任务变成人工智能算法，将硬件和系统软件都接入通用计算平台，并催生了曙光、汉王、科大讯飞等一批骨干企业。

符号计算系统的局限性在于其爆炸的计算时空复杂度，即符号计算系统只能解决线性增长问题，对于高维复杂空间问题是无法求解的，从而限制了能够处理问题的大小。同时因为符号计算系统是基于知识规则建立的，我们又无法对所有的常识用穷举法来进行枚举，它的应用范围就受到了很大的限制。随着第二次AI寒冬的到来，第一代智能计算机逐渐退出历史舞台。

## 深度学习计算系统(2014年)
直到2014年左右，智能计算进阶到第三阶段——深度学习计算系统。以杰弗里·辛顿（Geoffrey Hinton）等为代表的连接智能学派，以学习能力自动化为目标，发明了深度学习等新AI算法。通过深度神经元网络的自动学习，大幅提升了模型统计归纳的能力，在**模式识别**等应用效果上取得了巨大突破，某些场景的识别精度甚至超越了人类。以人脸识别为例，整个神经网络的训练过程相当于一个网络参数调整的过程，将大量的经过标注的人脸图片数据输入神经网络，然后进行网络间参数调整，让神经网络输出的结果的概率无限逼近真实结果。神经网络输出真实情况的概率越大，参数就越大，从而将知识和规则编码到网络参数中，这样只要数据足够多，就可以对各种大量的常识进行学习，通用性得到极大的提升。连接智能的应用更加广泛，包括语音识别、人脸识别、自动驾驶等。在计算载体方面，中国科学院计算技术研究所2013年提出了国际首个深度学习处理器架构，国际知名的硬件厂商英伟达（NVIDIA）持续发布了多款性能领先的通用GPU芯片，都是深度学习计算系统的典型代表。

注：**模式识别**是指用计算的方法根据样本的特征将样本划分到一定的类别中去，是通过计算机用数学方法来研究模式的自动处理和判读，把环境与客体统称为“模式”。以图像处理与计算机视觉、语音语言信息处理、脑网络组、类脑智能等为主要研究方向。

## 大模型计算系统(2020年)
智能计算发展的第四阶段是大模型计算系统(2020年)。在人工智能大模型技术的推动下，智能计算迈向新的高度。2020年，AI从“小模型+判别式”转向“大模型+生成式”，从传统的人脸识别、目标检测、文本分类，升级到如今的文本生成、3D数字人生成、图像生成、语音生成、视频生成。大语言模型在对话系统领域的一个典型应用是OpenAI公司的ChatGPT，它采用预训练基座大语言模型GPT-3，引入3000亿单词的训练语料，相当于互联网上所有英语文字的总和。其基本原理是：通过给它一个输入，让它预测下一个单词来训练模型，通过大量训练提升预测精确度，最终达到向它询问一个问题，大模型产生一个答案，与人即时对话。在基座大模型的基础上，再给它一些提示词进行有监督的指令微调，通过人类的<指令，回复>对逐渐让模型学会如何与人进行多轮对话；最后，通过人为设计和自动生成的奖励函数来进行强化学习迭代，逐步实现大模型与人类价值观的对齐。

大模型的特点是以“大”取胜，其中有三层含义：
1. 参数大，GPT-3就有1700亿个参数；
2. 训练数据大，ChatGPT大约用了3000亿个单词，570GB训练数据；
3. 算力需求大，GPT-3大约用了上万块V100 GPU进行训练。为满足大模型对智能算力爆炸式增加的需求，国内外都在大规模建设耗资巨大的新型智算中心，英伟达公司也推出了采用256个H100芯片，150TB海量GPU内存等构成的大模型智能计算系统。

大模型的出现带来了三个变革：
1. 一是技术上的规模定律（Scaling Law），即很多AI模型的精度在参数规模超过某个阈值后模型能力快速提升，其原因在科学界还不是非常清楚，有很大的争议。AI模型的性能与模型参数规模、数据集大小、算力总量三个变量成“对数线性关系”，因此可以通过增大模型的规模来不断提高模型的性能。目前最前沿的大模型GPT-4参数量已经达到了万亿到十万亿量级，并且仍在不断增长中；
2. 二是产业上算力需求爆炸式增长，千亿参数规模大模型的训练通常需要在数千乃至数万GPU卡上训练2-3个月时间，急剧增加的算力需求带动相关算力企业超高速发展，英伟达的市值接近两万亿美元，对于芯片企业以前从来没有发生过；
3. 三是社会上冲击劳动力市场，北京大学国家发展研究院与智联招聘联合发布的《AI大模型对我国劳动力市场潜在影响研究》报告指出，受影响最大的20个职业中财会、销售、文书位于前列，需要与人打交道并提供服务的体力劳动型工作，如人力资源、行政、后勤等反而相对更安全。

## 人工智能的技术发展方向
人工智能的技术前沿将朝着以下四个方向发展：
1. 第一个前沿方向为多模态大模型；
2. 第二个前沿方向为视频生成大模型；
3. 第三个前沿方向为具身智能；
4. 第四个前沿方向是AI4R(AI for Research)成为科学发现与技术发明的主要范式。

### 发展方向一：多模态大模型
从人类视角出发，人类智能是天然多模态的，人拥有眼、耳、鼻、舌、身、嘴(语言)，从AI视角出发，视觉，听觉等也都可以建模为**token**的序列，可采取与大语言模型相同的方法进行学习，并进一步与语言中的语义进行对齐，实现多模态对齐的智能能力。

注：**token**可翻译为词元，指自然语言处理过程中用来表示单词或短语的符号。token可以是单个字符,也可以是多个字符组成的序列。

### 发展方向二：视频生成大模型
OpenAI于2024年2月15日发布文生视频模型SORA，将视频生成时长从几秒钟大幅提升到一分钟，且在分辨率、画面真实度、时序一致性等方面都有显著提升。SORA的最大意义是它具备了世界模型的基本特征，即人类观察世界并进一步预测世界的能力。世界模型是建立在理解世界的基本物理常识（如，水往低处流等）之上，然后观察并预测下一秒将要发生什么事件。虽然SORA要成为世界模型仍然存在很多问题，但可以认为SORA学会了画面想象力和分钟级未来预测能力，这是世界模型的基础特征。

### 发展方向三：具身智能
具身智能指有身体并支持与物理世界进行交互的智能体，如机器人、无人车等，通过多模态大模型处理多种传感数据输入，由大模型生成运动指令对智能体进行驱动，替代传统基于规则或者数学公式的运动驱动方式，实现虚拟和现实的深度融合。因此，具有具身智能的机器人，可以聚集人工智能的三大流派：以神经网络为代表的连接主义，以知识工程为代表的符号主义和控制论相关的行为主义，三大流派可以同时作用在一个智能体，这预期会带来新的技术突破。

### 发展方向四：AI4R(AI for Research)
当前科学发现主要依赖于实验和人脑智慧，由人类进行大胆猜想、小心求证，信息技术无论是计算和数据，都只是起到一些辅助和验证的作用。相较于人类，人工智能在记忆力、高维复杂、全视野、推理深度、猜想等方面具有较大优势，是否能以AI为主进行一些科学发现和技术发明，大幅提升人类科学发现的效率，比如主动发现物理学规律、预测蛋白质结构、设计高性能芯片、高效合成新药等。因为人工智能大模型具有全量数据，具备上帝视角，通过深度学习的能力，可以比人向前看更多步数，如能实现从推断(inference)到推理(reasoning)的跃升，人工智能模型就有潜力具备爱因斯坦一样的想象力和科学猜想能力，极大提升人类科学发现的效率，打破人类的认知边界。这才是真正的颠覆所在。

最后，**通用人工智能**（Artificial General Intelligence，简称AGI）是一个极具挑战的话题，极具争论性。曾经有一个哲学家和一个神经科学家打赌：25年后（即2023年）科研人员是否能够揭示大脑如何实现意识？当时关于意识有两个流派，一个叫集成信息理论，一个叫全局网络工作空间理论，前者认为意识是由大脑中特定类型神经元连接形成的“结构”，后者指出意识是当信息通过互连网络传播到大脑区域时产生的。2023年，人们通过六个独立实验室进行了对抗性实验，结果与两种理论均不完全匹配，哲学家赢了，神经科学家输了。通过这一场赌约，可以看出人们总是希望人工智能能够了解人类的认知和大脑的奥秘。从物理学的视角看，物理学是对宏观世界有了透彻理解后，从量子物理起步开启了对微观世界的理解。智能世界与物理世界一样，都是具有巨大复杂度的研究对象，AI大模型仍然是通过数据驱动等研究宏观世界的方法，提高机器的智能水平，对智能宏观世界理解并不够，直接到神经系统微观世界寻找答案是困难的。人工智能自诞生以来，一直承载着人类关于智能与意识的种种梦想与幻想，也激励着人们不断探索。

注：**通用人工智能**是指拥有与人类相当甚至超过人类智能的人工智能类型。通用人工智能不仅能像人类一样进行感知、理解、学习和推理等基础思维能力，还能在不同领域灵活应用、快速学习和创造性思考。通用人工智能的研究目标是寻求统一的理论框架来解释各种智能现象。

## 参考资料
1. [《人工智能与智能计算的发展》](https://mp.weixin.qq.com/s/JMIE2HFGS-Jy7ai4z6BmQA)